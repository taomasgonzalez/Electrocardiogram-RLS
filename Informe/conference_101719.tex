\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{float}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Detection of heart anomalies by use of adaptive LMS and RLS filters in ECG signals*\\
}

\author{\IEEEauthorblockN{1\textsuperscript{st} Tom\'as Agust\'in Gonz\'alez Orlando}
\IEEEauthorblockA{\textit{Procesamiento Adaptativo de Se\~nales} \\
\textit{Instituto Tecnol\'ogico de Buenos Aires}\\
Buenos Aires, Argentina\\
togonzalez@itba.edu.ar}
\and
\IEEEauthorblockN{2\textsuperscript{nd} Ariel Santiago Nowik}
\IEEEauthorblockA{\textit{Procesamiento Adaptativo de Se\~nales} \\
\textit{Instituto Tecnol\'ogico de Buenos Aires}\\
Buenos Aires, Argentina\\
anowik@itba.edu.ar}
}

\maketitle

\begin{abstract}
An implementation of a heart anomaly detector using different adaptive filter structures is proposed.\par
The detection algorithm uses an Adaptive Recursive Filter (ARF), for which the impulse input signal is previously determined via a peak localization and time shift estimation algorithm. \par
The detection of each anomaly by itself is product of the direct observation of the magnitude of the ARF output.\par
The design and testing of the detector was based on the MIT-BIH Arrhythmia Database with an acceptable amount of false-negative and false-positive results. Heart anomalies are not classified by the proposed method, only detected.
\end{abstract}

\begin{IEEEkeywords}
ECG analysis, heart anomaly detection, Adaptive Filtering, LMS filters
\end{IEEEkeywords}


\section{Introduction}


\subsection{Electrocardiogram signals}

An Electrocardiogram (ECG) signal is a non invasive recording (electrodes are placed on the patient's skin) of the electrical activity of a heart. There are several places where the signals may be recorded, and usually as many as ten electrodes are used to perform an ECG, where the polarization and repolarization of the heart muscles are recorded. \par
An ECG portrays an incredibly large amount of information from the patient, such as the rate and rhythm of heartbeats, the size and position of the heart chambers, the presence of any damage to the heart's muscle cells or conduction system, the effects of heart drugs, and the function of implanted pacemakers.\par
These polarization cycles form the main three components of a heart signal, which are listed as follows:
\begin{itemize}
\item \underline{P-wave} : Depolarization of the atria. This component is frequently the one with the lowest amplitude.
\item \underline{QRS complex}: Depolarization of the ventricles. In the QRS complex a peak of high frequency and the highest amplitude is detected. 
\item \underline{T-wave}: Repolarization of the ventricles.
\end{itemize} 

\begin{figure}[H]
\centerline{\includegraphics[scale=0.3]{SinusRhythmLabels}}
\caption{Main components of an ECG signal}
\label{fig}
\end{figure}

These components were enumerated in their usual order of appearance. However, some patients with heart abnormalities exhibit a P-wave that superposes over the QRS complex, so the techniques developed below should take into account this factor when analysing the ECG signal even with no previous knowledge of the abnormality. Adaptive filters have been proven efficient in such cases. \par

\subsection{Adaptive Recursive Filters}

An Adaptive Recursive Filter (ARF) is an adaptive filter whose coefficients change so that when it is adapted, its impulse response converges to a single pseudo-period of an ideally periodic signal. The ARF is therefore applied to signals that are known to have periodic behaviour with considerably small changr
s through time in both its pseudo-periods and its fundamental period.\par
The signal in question may be then considered to be stationary between time intervals of a given length.\par
A diagram of the ARF, taken from \cite{b1} is shown below:

\begin{figure}[H]
\centerline{\includegraphics[scale=0.7]{ARF_diagram.png}}
\caption{Basic diagram of an ARF}
\label{fig}
\end{figure}

The ARF has two input signals: \par
The original (ECG) signal and a signal which contains only impulses in the beginning of each pseudo period of the original signal. Via this method, the coefficients of the filter will be updated one by one in each iteration, so that if $w_k$ is the k-th coefficient of the filter, $w_k$ will be updated in one iteration of the algorithm and then  $w_{k+1}$ will be updated in the next iteration. This is because in each iteration, the filter will compare its impulse response at a single time (hence, at a single coefficient) with the input signal at that specific time, and the error derived from that comparison will be fed to the adaptive filter so as to minimize its cost function.
\section{Cleansing of the dataset}

Before any algorithm is proposed, there are certain aspects about the use of the dataset and its annotations that should be clarified:\par
\begin{itemize}
\item Annotations about the poor quality of the signals in a specific point in time (that sometimes made the signal unreadable at that point) were not considered as real anomalies. The detection of this points as anomalies would therefore signify an error in the algorithm when visualizing the efectiveness of the filter. This is not necessarily true, as the filter should perhaps consider excessive noise as an anomaly, but this criteria was taken so that the accuracy measurements that are presented when validating results represent the worst case scenario.
\item Annotations that implied comments from the experts were not considered as anomalies either. This was chosen to be this way after inspection of a large amount of comments and their significance in the dataset.
\item All other annotations were considered anomalies and were turned into an anomaly of type `A', so as not to discriminate between them.
\end{itemize}

\section{LMS prediction}

The first approach taken was the implementation of an adaptive predictor based on the following diagram:

\begin{figure}[H]
\centerline{\includegraphics[scale=0.4]{prediction.png}}
\caption{Adaptive predictor diagram}
\label{fig}
\end{figure}

The implementation achieved its desired purpose of predicting the signal, as shown in the following figure:

\begin{figure}[H]
\centerline{\includegraphics[scale=0.35]{imagenes/prediction.png}}
\caption{Fragment of Signal 100 of the MIT-BIH Arrhythmia Database and the predictor's response to it.}
\label{fig}
\end{figure}

The magnitude of the error signal was afterwards processed in order to get its peaks, which where considered anomalies when its amplitude exceeded a designated value. This method of anomaly detection did not manage to achieve acceptable results as the predictor error tends to raise when the ECG signal has high frequency changes, and so the the peaks of the QRS complex were also taken as anomalies. \par
Although this problem disqualified the method, if the QRS complex is detected via a previous analysis of the signal, discarding the false positives that appear with its peaks may be a path to be followed in future investigations.\par

\section{Detection}

The detection of each anomaly consists of applying the detection algorithm to the entire ECG signal or a portion of it. The steps of this algorithm are in line with the arrythmia detection method stated by \cite{b1}:

\begin{enumerate}
\item Find the peaks of each QRS complex.
\item Generate an impulse signal in which each impulse coincides with the beggining of the QRS complex.  
\item Feed the ARF with both the new impulse signal and the ECG. 
\item Get the error signal of the ARF after processing the inputs.
\item Identify the peaks of the absolute error signal and select those points in which these peaks may signify an anomaly.
\end{enumerate}

Choosing to generate an impulse at the start of the QRS complex and not at the start of the P-wave is the solution for the possibility of an abnormality in the P-wave that may provoke it to overlap with other components of the signal. The ARF will make its impulse response copy by default the QRS complex and the T-wave, and in such case that no overlapping ocurrs, the P-wave will also be shown in the impulse response of the filter.

\subsection{Detection of the QRS complex}

The localization of the QRS complex is based on the detection of high amplitude peaks. This may be done by assuming signal stationarity for some interval of time. Fifteen pseudo-periods of the signal has been proven an effective amount of time. The period has been estimated with the a priori knowledge of an ECG: The period of a heart signal is of approximately 1 beat per second. Taking this into account and the fact that the sample rate of the MIT-BIH Database is 360 Hz, a number of 350 samples was the estimated length of a heart beat. \par
After defining the stationary interval, the signal is then converted to its energy signal by simply squaring each value. Converting the signal to its energy signal for peak detection has two advantages:

\begin{enumerate}
\item All values of the energy signal will be non negative.
\item Greater values will be weigthed as more important and significative than smaller values as pondered by the square function.
\end{enumerate}

A peak will be detected each time a sample of the energy signal has a value that is at least 0.55 times the maximum value of the interval.

\subsection{Generation of the impulse signal}

As each peak of the QRS complex corresponds to the R component of the signal, a time shift should be applied so that the generated impulse signal will have its impulse assigned to the beginning of the QRS complex. This time shift should also be estimated in a proportion of the estimated pseudo-period time, although this estimation may also be updated every time a new peak is detected.

\subsection{Design and implementation of the ARF}

The implementation of the ARF was done with two different algorithms: The LMS and the RLS algorithm.
Given the particular structure of the ARF that implies inputting an impulse signal and consequently updating only one coefficient on each iteration, it is expected that the use of RLS will not convey improvements of great significance to the filter, relative to using LMS. \par 
Although the previously mentioned condition regarding the update of the coefficients of the ARF structure, both the implementation with LMS and the one with RLS were designed so that an update of multiple coefficients in the same iteration, in addition to the single coefficient update, was also made. \par
The results of the single and multiple updates of the LMS and RLS algorithms were afterwards compared. These led to the conclusion that there was practically no difference in the resulting error between updating multiple coefficients in contrast with updating a single coefficient, but the computational cost, and hence the convergence velocity of the algorithm, was by far cheaper when using the LMS-single update method. As a consequence, the LMS-single update method is the one used when showing the results.\par
We will now develop the particulars of all the implementations.

\subsubsection{LMS implementation} 
The ARF was implemented using the same LMS filter used in the adaptive predictor filter. No variants of the LMS algorithm were used, as its accuracy was more than acceptable. The convergence step $\mu$ of the LMS algorithm was chosen prioritizing the convergence velocity of the algorithm so that the filter could be used in almost real time like applications. With this objective in mind, $\mu$ was firstly given an initial value that made the algorithm unstable and then was decremented until the filter converged for all ECG signals in the database. \par
\begin{figure}[H]
\centerline{\includegraphics[scale=0.6]{imagenes/LMS_filter.png}}
\caption{Convergence of LMS Filer $\mu=0.5$}
\label{fig}
\end{figure}

\subsubsection{RLS implementation}
The RLS algorithm made syntetized the signal to predict correctly the desired signal.
The convergence step $\mu$ of the RLS algorithm is reduced to very specific values, with $\mu \epsilon [0.9; 1]$. The best value for $\mu$ being of course the lowest $\mu = 0.9$ for greater convergence velocity. The initial values of the filter needed to be zero to ensure a faster convergence. 
\begin{figure}[H]
\centerline{\includegraphics[scale=0.6]{imagenes/RLS_filter.png}}
\caption{Convergence of RLS Filer $\mu=0.9$}
\label{fig}
\end{figure}

\subsubsection{LMS and RLS comparison} 

The final version of the ARF filter (LMS single-update) was fed with the generated impulse signal and the original ECG signal. Although the output signal was available, it was only required to verify that the impulse response of the filter was indeed adapting to the original signal (In the particular case of the ARF, this step is equivalent to coefficient tracking). This was done both graphically and by observation of the error signal and the quadratic error of the filter. The conclusion was that there was no determinant enhancement by changing LMS to RLS algorithm. Even more, RLS algorithm was much slower thus impractical. \par

\begin{figure}[H]
\centerline{\includegraphics[scale=0.6]{imagenes/filter_comparison.png}}
\caption{Signal (up), LMS filter (middle), RLS filter (down)}
\label{fig}
\end{figure}

\subsection{Baseline Wander and noise handling}

Due to muscle movements and the noise frequencies of the electric line, the signals baseline was variable along time. This caused problems when determining peaks and when analysing the error signal of the ARF, which resulted in the appearance of several false positives, as the impulse signal input of the ARF was corrupted and so the filter could not adapt its coefficients correctly. \par
Numerous methods for reducing the baseline wander were tried, such as:
\begin{itemize}
\item Interference elimination of the line frequency using the common mode between the two available ECG signals as a reference and the analysed signal as input.
\item Non adaptive notch and bandpass filters between 0.7 Hz and 125Hz as stated in \cite{b2}
\item Lineal detrending of the signal.
\end{itemize}

In the end, the use a high-pass filter of a 0.1Hz cut-off frequency was the method that proved more successful to remove the baseline wander.\par
Using the common mode between the two available ECG signals as a reference and the analysed signal as input showed unsatisfactory results because the common mode of the two heart signals, although carried the line noise, it also contained important information about the patient's condition and his/her heart normal behaviour.\par
No method for handling the powerline 60 Hz noise without severely affecting the transient response of the filter was found. This is due to the fact that the MIT-BIH Arrhythmia database did not provide 60 Hz noise that was in phase with the ECG signal, as if this extra data (that could only be taken at the moment of performing the ECG) was available, an adaptive interference cancellation scheme/filter might have been useful. \par
The reason why adaptive and non adaptive notch filters do not achieve acceptable results were already stated by. Using the substraction procedure is proposed in this article. \par


\section{Criteria for recognizing heart anomalies}
Until now we have developed a system with several stages: first a filter to remove low frequencies trends, then a peak detector whose output was fed to the ARF. The error signal produced by the ARF will then contain information that may be easily extracted to detect anomalies. At this point, all that is left to do is make the extraction algorithm\par
\begin{figure}[H]
\centerline{\includegraphics[scale=0.55]{imagenes/diagram}}
\caption{Global system overview}
\label{fig}
\end{figure}

To develop our algorithm we could make another peak detector, however, after the thorough inspection of the available ECG signals and some trials and errors, we arrived to the conclusion that the energy of the error signal between two peaks is a more accurate metric for anomaly detection in that specific region. This is because electrocardiogram failure is more of a distributed problem over the whole pseudo-period rather than a localized event.\par

The designed algorithm calculates the energy of each pseudo-period of the error signal. If said energy is sufficiently high (higher than a calibrated value reached by trial and error) the algorithm reports an anomaly. A weighted average was used to assign an epicenter to the anomaly, thus being able to compare these epicenters with the real times of each anomaly, taken from the annotations of the MIT-BIH database.

\begin{figure}[H]
\centerline{\includegraphics[scale=0.7]{imagenes/anomalyAlgo}}
\caption{Anomaly detection algorithm}
\label{fig}
\end{figure}

An Accuracy test was developed  to measure how effective the detection method was and to make an outlier analysis that could lead us into solutions for particular failures or new algorithms.

\section{Accuracy test}
The comparison module from the diagram of Figure 5 measures the performance of the algorithm. Its inputs are both the detected anomalies and the real anomalies.\par

Ideally, based on the measured performance, the other 4 blocks of the global system (highpassH, peakDetector, ARF, anommalyDetector) would be changed and improved continually in order to enhance its functionality.\par

Two different kinds of accuracy tests were done. This tests were designed to measure and contrast the amount of false-positives and false-negatives, which are defined as follows:\par
\begin{itemize}
\item \underline{false-positive:} The algorithm wrongly detects an anomaly when no real anomaly is in the database annotations at that specific time of the signal.
\item \underline{false-negative:} The algorithm does not detect an anomaly although a real anomaly exists in the database annotations at that specific time of the signal.
\end{itemize}

It should be noted that, although these two errors in the algorithm may seem very similar, a false-negative is considered of much more importance than a false-positive. The reason of such a distinction is due to the severe implications of having a patient diagnosed as healthy when he is really not as opposite to detecting a condition in a specific time, which could be easily and quickly corrected by an expert.\par

The algorithm consisted of an iteration over the detected failure points that checked if a real failure was near enough. By trial and error we found the range size to select how far the detected anomaly and the real anomaly should be considered the same.  
\begin{figure}[H]
\centerline{\includegraphics[scale=0.8]{imagenes/comparisonAlgo.png}}
\caption{Correctly detected/Detected}
\label{fig}
\end{figure}

We computed an array to optimize the calculation, that contained 1s if the position was near enough to a real failure point (and 0s otherwise). With this array, we could check in $O(1)$ if a failure point was correcly selected. This algorithm would be efficient if the failure real points are much lower than the total points, because setting lots of 1s in the array can be time consuming leading to a slow algorithm. There could be better methods that might involve sorting the failure points arrays, but for our application this method was good enough. In the next picture we can visualize computed array.

\begin{figure}[H]
\centerline{\includegraphics[scale=0.8]{imagenes/arrayExplain.png}}
\caption{Correctly detected/Detected}
\label{fig}
\end{figure}


We have run the accuracy test with all signals from the database.
These two figures are the results. We made a graphic plot where each row has the results from one of each of the signals presented.

\begin{figure}[H]
\centerline{\includegraphics[scale=0.6]{imagenes/EfectividadDetectados}}
\caption{Correctly detected/Detected}
\label{fig}
\end{figure}

\begin{figure}[H]
\centerline{\includegraphics[scale=0.6]{imagenes/EfectividadExistentes}}
\caption{Failures detected/Total heart failures}
\label{fig}
\end{figure}

\section{Analysis and validation of results}

The results are very disperse. In some cases there are very low accuracy rate. From the analysis of these cases, we discovered two main reasons for these inaccuracies: \par
\begin{enumerate}
\item Every case in which a signal has permanent anomalies, the adapted filter will learn that the anomaly is the correct pattern, thus the algorithm will almost certainly fail, as it is built for causal failures, not permanent ones. To make a more advanced algorithm that deals with these cases, the designed method should take into account information of how the cardiac signals are in both healthy and unhealthy hearts. This would imply the necessity of a more complete database to train the algorithm.
\item In those cases in which there is a failure that has no relationship with the signal form but with a period mismatch of heart signals, the algorithm does not detect an anomaly as there is no input control of the impulse signal. This case could more easily handled, by adding a system before the ARF that checks if the peak distance is healthy. 
\end{enumerate}

\section{Conclusion}
We developed a simple method using adaptive filters to detect some kinds of cardiac failures and find a way to verify it worked right in lot of cases using the MIT-BIH database. We studied different improvements that could be done to the different stages of the method, and found the limitations of the used methodology. It is very probable that the ideas we used are key for other more advance methods, that are currently out of our scope of knowledge.

\begin{thebibliography}{00}
\bibitem{b1} Nitish V. Thakor and Yi-Sheng Zhu, ``Applications of Adaptive Filtering to ECG Analysis :
Noise Cancellation and Arrhythmia Detection'', IEEE Transactions On Biomedical Engineering. Vol. 18. No 8. August 1991.
\bibitem{b2} J. A. Van Alste and T. S. Schilder``Removal of Base-Line Wander and Power-Line Interference from the ECG by an Efficient FIR Filter with a Reduced Number of Taps'', IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. BME-32, NO. 12, DECEMBER 1985.
\bibitem{b3} https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1232857/ US National Library of Medicine.
\end{thebibliography}
\end{document}

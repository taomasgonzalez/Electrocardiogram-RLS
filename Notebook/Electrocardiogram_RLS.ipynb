{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Electrocardiogram_anomalies.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taomasgonzalez/Electrocardiogram-RLS/blob/master/Notebook/Electrocardiogram_RLS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Nwb3l0_PSXn6"
      },
      "source": [
        "# Detectando anomalías en Electrocardiogramas (ECG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wYZopBc1Sf6d"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m20ItMNTSJbY"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VwZwc-ZOk_Q4"
      },
      "source": [
        "Instalamos las librerías necesarias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w9tsBoIOk95q",
        "colab": {}
      },
      "source": [
        "!pip install wfdb\n",
        "!pip install padasip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ODah1rLdlDCx"
      },
      "source": [
        "Importamos las librerías necesarias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S1Fv6b6jS0_X",
        "colab": {}
      },
      "source": [
        "# https://github.com/MIT-LCP/wfdb-python\n",
        "# https://wfdb.readthedocs.io/en/latest/\n",
        "import numpy as np\n",
        "import wfdb\n",
        "import matplotlib.pyplot as plt\n",
        "import padasip as pa\n",
        "from scipy import signal as scsig\n",
        "from scipy.signal import detrend\n",
        "from scipy.signal import find_peaks\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qI7z9zQ3g6_B"
      },
      "source": [
        "Clonamos el repositorio de github:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hluVAXFOg6VQ",
        "colab": {}
      },
      "source": [
        "!git clone \"https://github.com/taomasgonzalez/Electrocardiogram-LMS.git\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vNYHtgB_SL_p"
      },
      "source": [
        "## Obtención de los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UmTtaloigJCD"
      },
      "source": [
        "Obtenemos los datos de electrocardiogramas realizados a múltiples pacientes del MIT-BIH Arrhythmia Database (https://physionet.org/content/mitdb/1.0.0/).\n",
        "\n",
        "Para más información sobre su contenido y las particularidades con las que los datos fueron obtenidos, visitar la página."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qlTBKhEXg18b"
      },
      "source": [
        "### Definición de funciones de obtención de datos del dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cq92-lOISA7U",
        "colab": {}
      },
      "source": [
        "def get_data(file_path, sampto='end'):\n",
        "  \"\"\"\n",
        "  get_data devuelve las señales del primer y segundo canal de un archivo que cumple con el estándar wfdb,\n",
        "  la metadata del mismo y las anotaciones del mismo en caso de haberlas (archivo con el mismo nombre pero con extensión .atr)\n",
        "  \n",
        "  Parámetros:\n",
        "    file_path: path del archivo de donde conseguir las señales a leer.\n",
        "    sampto: cantidad de samples a leer. Si 'end', lee todas las samples del archivo.\n",
        "  Returns:\n",
        "    signal_0: Señal del primer canal.\n",
        "    signal_1: Señal del segundo canal.\n",
        "    metadata: metadata que contiene, entre otras cosas, la sample frequency utilizada para tomar los datos.\n",
        "    annotation: anotaciones correspondientes al archivo\n",
        "  \"\"\"\n",
        "  # Cada columna de la matriz signals es un canal de las señales grabadas del paciente(signals[0] es el primer canal)\n",
        "  # metadata tiene información como la sample frequency, importante para el resto del trabajo.\n",
        "  signals, metadata = wfdb.rdsamp(record_name=file_path, sampto=sampto)\n",
        "  annotation = wfdb.rdann(record_name=file_path, extension='atr', sampto=sampto)\n",
        "  \n",
        "  return signals[:,0], signals[:,1], metadata, annotation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZuynzSBr7Etp"
      },
      "source": [
        "### Obtención de las señales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gPogWRtuqylG"
      },
      "source": [
        "Definimos los archivos están presentes en dataset, que serán los archivos que extraeremos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8uWZ7-Mzqs5e",
        "colab": {}
      },
      "source": [
        "all_signals = {str(i): dict() for j in (range(100, 125), range(200, 224)) for i in j}\n",
        "# borramos del dictionary a los archivos que no estan pero que fueron agregados por comodidad\n",
        "for i in ['110', '120', '204','206','211','216','218']: del all_signals[i]   \n",
        "all_signals['228'] = None\n",
        "for i in range(230,235) : all_signals[str(i)] = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6DvQpW8xf9kI"
      },
      "source": [
        "Obtenemos las señales de cada canal, en conjunto con su metadata y las anotaciones que corresponden a la presencia de anomalía o no."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QaUu3AfqUFKM",
        "colab": {}
      },
      "source": [
        "for signal_name in all_signals.keys():\n",
        "  upper_signal, lower_signal, metadata, annotations =  get_data(file_path='/content/Electrocardiogram-LMS/data/' + signal_name,sampto=None)\n",
        "  all_signals[signal_name] = {'upper' : upper_signal, 'lower' : lower_signal, 'meta':metadata, 'annot': annotations} "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "50Ae_uqKf2Cr"
      },
      "source": [
        "Visualizamos alguna de las señales:\n",
        "\n",
        "Hacemos un plot de los primeros 1000 samples de una de las señales de uno de los pacientes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QgddDbxMf89R",
        "colab": {}
      },
      "source": [
        "plt.plot(all_signals[list(all_signals.keys())[0]]['upper'][:1000])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K9knumiI3Wkw"
      },
      "source": [
        "### Anotaciones\n",
        "\n",
        "Visualizamos la clase anotaciones, cómo está estructurada internamente.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q7OE90KX5F3a",
        "colab": {}
      },
      "source": [
        "anot = all_signals[list(all_signals.keys())[0]]['annot']\n",
        "attrs = vars(anot)\n",
        "print ('\\n'.join(\"%s: %s\" % item for item in attrs.items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lq1eGWMC45D3"
      },
      "source": [
        "Cambiamos todas las anotaciones a un formato binario de tipo \"anómala\" ('A') o \"no anómala\" ('N'). \n",
        "Visualizamos luego el resultado de un fragmento de una señal de un paciente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOhB5AkXyZ76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "abnormalities = ['V','L','F', 'Q', 'R', 'x', 'a','J', 'j', 'E', '+', 'S', '!', '[', ']', 'e', 'f']\n",
        "junk = ['~', '|', '/', '\"'] #consideradas anotaciones que no son anomalias en la mayoria de los casos\n",
        "for key in all_signals.keys():\n",
        "  anot = all_signals[key]['annot']    \n",
        "  print([key]+ [i for i in anot.symbol if i not in ['A', 'N'] + abnormalities + junk])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YhGYPhEMtFhb",
        "colab": {}
      },
      "source": [
        "for key in all_signals.keys():\n",
        "  anot = all_signals[key]['annot']    \n",
        "  for i in range(len(anot.symbol)):\n",
        "    if anot.symbol[i] is not 'N':\n",
        "      if anot.symbol[i] in junk:\n",
        "        anot.symbol[i] = 'N'\n",
        "      else :\n",
        "        anot.symbol[i] = 'A' \n",
        "    # anot.symbol = ['A' if i is not 'N' else 'N' for i in anot.symbol]\n",
        "\n",
        "  # guardamos el sample en el que se produce la anomalia y el indice de la misma en el anot.sample \n",
        "  all_signals[key]['anomalies'] = {anot.sample[i] : i  for i in range(len(anot.symbol)) if anot.symbol[i] is 'A'}\n",
        "  # guardamos el sample en el que se produce la anotacion normal y el indice de la misma en el anot.sample \n",
        "  all_signals[key]['not_anomalies'] = {anot.sample[i] : i  for i in range(len(anot.symbol)) if anot.symbol[i] is 'N'}\n",
        "   \n",
        "anot = all_signals[list(all_signals.keys())[0]]['annot']\n",
        "plt.plot(anot.symbol[0:1000])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1bTjTwvNt_U",
        "colab_type": "text"
      },
      "source": [
        "### Eliminación de ruido\n",
        "\n",
        "El ruido principal que afectará al comportamiento del filtro a implementar es aquel que produce al baseline wonder, además del ruido de línea. Se elimina el ruido de baja frecuencia aplicando un pasaltos de frecuencia apropiada (0.1 Hz)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-jp5CtWOM_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def noise_filtering(signal):\n",
        "    b, a = scsig.butter(4, 0.1 * 2 * np.pi, btype='highpass', fs=360)\n",
        "    return scsig.filtfilt(b, a, signal)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8d5QB4-vSNtp"
      },
      "source": [
        "## Implementación del filtro adaptativo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tE43VmsOD24u"
      },
      "source": [
        "### Implementación del filtro"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TUFxamWS_fhN",
        "colab": {}
      },
      "source": [
        "# https://matousc89.github.io/padasip/sources/filters/lms.html#references\n",
        "# https://matousc89.github.io/padasip/_modules/padasip/filters/lms.html#FilterLMS\n",
        "class FilterLMS():\n",
        "    \"\"\"\n",
        "    This class represents an adaptive LMS filter.\n",
        "\n",
        "    **Args:**\n",
        "\n",
        "    * `n` : length of filter (integer) - how many input is input array\n",
        "      (row of input matrix)\n",
        "\n",
        "    **Kwargs:**\n",
        "\n",
        "    * `mu` : learning rate (float). Also known as step size. If it is too slow,\n",
        "      the filter may have bad performance. If it is too high,\n",
        "      the filter will be unstable. The default value can be unstable\n",
        "      for ill-conditioned input data.\n",
        "\n",
        "    * `w` : initial weights of filter. Possible values are:\n",
        "        \n",
        "        * array with initial weights (1 dimensional array) of filter size\n",
        "    \n",
        "        * \"random\" : create random weights\n",
        "        \n",
        "        * \"zeros\" : create zero value weights\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, n, w='zeros', mu=0.01):\n",
        "        self.n = n\n",
        "        self.mu = mu\n",
        "        if w is 'zeros':\n",
        "          self.w = np.zeros(self.n)\n",
        "        else:  \n",
        "          if len(w) is self.n: \n",
        "            self.w = np.array(w)\n",
        "          else:\n",
        "            raise ValueError('The size of filter must be the same as the size of the weights vector')\n",
        "        \n",
        "        self.w_history = False\n",
        "        self.input = np.array([])\n",
        "        self.desired_response = np.array([])\n",
        "        self.y = np.array([])\n",
        "        self.e = np.array([])\n",
        "        \n",
        "    def adapt(self, d, x):\n",
        "        \"\"\"\n",
        "        Adapt weights according one desired value and its input.\n",
        "\n",
        "        **Args:**\n",
        "\n",
        "        * `d` : desired value (float)\n",
        "\n",
        "        * `x` : input array (1-dimensional array)\n",
        "        \"\"\"\n",
        "        y = np.dot(self.w, x)\n",
        "        e = d - y\n",
        "        self.w += self.mu * e * x        \n",
        "        return y, e  \n",
        "      \n",
        "    def run(self, input_signal, desired_response):\n",
        "      self.desired_response = desired_response[self.n+1:]\n",
        "      self.input_signal = input_signal\n",
        "      self.y = np.array([])\n",
        "      self.e = np.array([])\n",
        "      \n",
        "      for i in range(len(self.desired_response)):\n",
        "        if i+self.n <= len(self.input_signal):\n",
        "          y, e = self.adapt(self.desired_response[i], self.input_signal[i:i+self.n])\n",
        "          self.y = np.concatenate((self.y, np.array([y])), axis=0)\n",
        "          self.e = np.concatenate((self.e, np.array([e])), axis=0)\n",
        "        else:\n",
        "          break\n",
        "        \n",
        "      return self.y, self.e"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IHdMwdkWD8T1"
      },
      "source": [
        "### Control gráfico para el análisis del filtro"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q2-bkeLoD_Cd",
        "colab": {}
      },
      "source": [
        "def plot_signal_vs_predicted(signal, predicted, error, sampling_size):\n",
        "  plt.figure(figsize=(15,9))\n",
        "\n",
        "  last_n_samples = 1000\n",
        "  plt.subplot(211);plt.title(\"Adaptation\");plt.xlabel(\"samples - k\")\n",
        "  plt.plot(signal[sampling_size-last_n_samples:],\"b\", label=\"d - target\")\n",
        "  plt.plot(predicted[sampling_size-last_n_samples:],\"g\", label=\"y - output\");plt.legend()\n",
        "\n",
        "  plt.subplot(212);plt.title(\"Filter error\");plt.xlabel(\"samples - k\")\n",
        "  # plt.plot(10*np.log10(error**2),\"r\", label=\"e^2 - squared error [dB]\");plt.legend()\n",
        "  plt.plot(error[sampling_size-last_n_samples:],\"r\", label=\"error\");plt.legend()\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Hv3DjRyMEDTI"
      },
      "source": [
        "### Prueba del filtro aplicado a los datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O41SdYB55OlT",
        "colab": {}
      },
      "source": [
        "# filter_size = 100\n",
        "# predictor_filter = FilterLMS(n=filter_size, w='zeros', mu=0.005)\n",
        "# sampling_size = 300000\n",
        "# upper_signal = all_signals[list(all_signals.keys())[0]]['upper'][:sampling_size]\n",
        "# y, e = predictor_filter.run(input_signal=upper_signal, desired_response=upper_signal)\n",
        "# y = np.append(np.zeros(filter_size), y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v750wyqnEGVA"
      },
      "source": [
        "Se grafica para un intervalo sano (sin anomalías)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LuzB6i7Y7bJb",
        "colab": {}
      },
      "source": [
        "# plot_signal_vs_predicted(signal=upper_signal, predicted=y, error=e, sampling_size=sampling_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tV5FZRpMEL5n"
      },
      "source": [
        "Se grafica ahora un intervalo con anomalías"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3Bnxqub7DypY",
        "colab": {}
      },
      "source": [
        "# anot = all_signals[list(all_signals.keys())[0]]['annot']\n",
        "# selected = anot.sample[np.logical_and(anot.sample > 99000, anot.sample < 100000)]\n",
        "# anom = all_signals[list(all_signals.keys())[0]]['anomalies']\n",
        "# for s in selected:\n",
        "#   if s in anom:\n",
        "#     first = s-500\n",
        "#     last = s+500\n",
        "#     print(first)\n",
        "#     break\n",
        "    \n",
        "# detected = np.arange(len(e[60000:]))[abs(e[60000:]) > 0.485 ]\n",
        "# print(detected + 60000)\n",
        "# print(list(all_signals[list(all_signals.keys())[0]]['anomalies'].keys()))\n",
        "# plt.figure(figsize=(15,9))\n",
        "\n",
        "# last_n_samples = 1000\n",
        "# plt.subplot(211);plt.title(\"Adaptation\");plt.xlabel(\"samples - k\")\n",
        "# plt.plot(upper_signal[first:last],\"b\", label=\"d - target\")\n",
        "# plt.plot(y[first:last],\"g\", label=\"y - output\");plt.legend()\n",
        "\n",
        "# plt.subplot(212);plt.title(\"Filter error\");plt.xlabel(\"samples - k\")\n",
        "# # plt.plot(10*np.log10(error**2),\"r\", label=\"e^2 - squared error [dB]\");plt.legend()\n",
        "# plt.plot(e[first:last],\"r\", label=\"error\");plt.legend()\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UDuzwl8xMqFS"
      },
      "source": [
        "## Implementación del detector de anomalías\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0KqxUZ-FQIf",
        "colab_type": "text"
      },
      "source": [
        "### Implementación del filtro ARF\n",
        "\n",
        "Se implementa a continuación el **filtro ARF** (Adaptative recursive filter) para generar la señal de error de predicción que se utilizará para la detección de anomalías."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_ayd2eZJhc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class filterARF:\n",
        "    def __init__(self, n, mu):\n",
        "        self.w = np.zeros(n + 1)\n",
        "        self.n = n\n",
        "        self.mu = mu\n",
        "\n",
        "        self.w[0] = 1\n",
        "\n",
        "    def train(self, u, d): # entrenamos el filtro con una señal de impulsos y la señal verdadera\n",
        "        y = np.zeros(len(u))\n",
        "        e = np.zeros(len(u))\n",
        "\n",
        "        last_impulse_position = -1\n",
        "\n",
        "        for i in range(len(u)):\n",
        "            if i + 1 >= self.n + 1:\n",
        "                y[i] = np.dot(self.w, np.flip(u[i + 1 - (self.n + 1):i + 1]))\n",
        "            else:\n",
        "                y[i] = np.dot(self.w[:i + 1], np.flip(u[:i + 1]))\n",
        "\n",
        "            if u[i] == 1:\n",
        "                last_impulse_position = i\n",
        "\n",
        "            # calculo error\n",
        "            e[i] = d[i] - y[i]\n",
        "\n",
        "            # actualizo coeficientes\n",
        "            if last_impulse_position != -1:\n",
        "                k = i - last_impulse_position\n",
        "                if k <= self.n:\n",
        "                    self.w[k] += 2 * self.mu * e[i]# actualizo coeficiente k-esimo\n",
        "\n",
        "        return y, e\n",
        "\n",
        "    def run(self, u, d): # ejecutamos el filtro, obtenemos el error, no actualizamos coeficientes\n",
        "        y = np.zeros(len(u))\n",
        "        e = np.zeros(len(u))\n",
        "        for i in range(len(u)):\n",
        "            if i + 1 >= self.n + 1:\n",
        "                y[i] = np.dot(self.w, np.flip(u[i + 1 - (self.n + 1):i + 1]))\n",
        "            else:\n",
        "                y[i] = np.dot(self.w[:i + 1], np.flip(u[:i + 1]))\n",
        "\n",
        "            # calculo error\n",
        "                e[i] = d[i] - y[i]\n",
        "\n",
        "        return y, e"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5V1duKSuMQo",
        "colab_type": "text"
      },
      "source": [
        "### Detector del complejo QRS mediante la detección de los picos R\n",
        "\n",
        "La detección del complejo QRS servirá para generar la señal de impulsos que será entrada del filtro ARF en conjunto a la señal de ECG original."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8oAGPXoM1va",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getPeaks(signal, fs, min_distance, impulse_distance = 0):\n",
        "    \"\"\"\n",
        "    signal: samples\n",
        "    min_distance: distance of peaks\n",
        "    fs: sample frecuency \n",
        "    \"\"\"\n",
        "    power_signal = np.power(signal,2)\n",
        "\n",
        "    # Consideramos que la señal no variara considerablemente en al menos 10 periodos del filtro\n",
        "    stationarity_size = 10*500\n",
        "\n",
        "    max_value = max(power_signal[:stationarity_size]) # maximo valor de la potencia en el primer intervalo estacionario\n",
        "\n",
        "    peakSignal = np.zeros(len(signal)) # señal donde almacenamos los picos\n",
        "\n",
        "    counter = 0\n",
        "    impulse_ticks = int(impulse_distance * fs)\n",
        "    \n",
        "    for i in range(len(signal)):\n",
        "      if i % stationarity_size == 0:\n",
        "        max_value = max(power_signal[:stationarity_size])\n",
        "      \n",
        "      if counter > 0:\n",
        "        counter -= 1\n",
        "      elif power_signal[i] > max_value * 0.45:\n",
        "        counter = min_distance * fs\n",
        "        if i > impulse_ticks:\n",
        "          peakSignal[i - impulse_ticks] = 1\n",
        "\n",
        "    return peakSignal"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2roZt2CNSP4K"
      },
      "source": [
        "### Probando al ARF\n",
        "\n",
        "Se busca que la señal de error del ARF tenga picos coincidentes con las anomalías, ya que se utilizará a la misma para la detección de anomalías."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGXoxOhTx7rZ",
        "colab_type": "text"
      },
      "source": [
        "#### Señal de prueba"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFrHJEiFKRFx",
        "colab_type": "text"
      },
      "source": [
        "Se procede a probar el detector usando la señal 202 que tiene un conjunto de señales cardiacas válidas en su inicio.\n",
        "\n",
        "Extraemos la señal y definimos un tiempo de prueba:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4VLL5QTvW6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fs = 360\n",
        "timespan = 400\n",
        "time_cycle = 1.4\n",
        "# señal = no_noise_signal\n",
        "señal = all_signals[\"202\"][\"upper\"][:timespan*fs]\n",
        "t = np.arange(len(señal)) / fs\n",
        "errores = list(all_signals[\"202\"][\"anomalies\"].keys())\n",
        "errores = [ float(errores[i]) / fs for i in range(len(errores))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBsUmaRIx-mn",
        "colab_type": "text"
      },
      "source": [
        "#### Análisis gráfico de la salida del ARF y contrastación con las anomalías de la base de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PW-l6oPvcf3",
        "colab_type": "text"
      },
      "source": [
        "Se procederá a graficar aquellos valores que deberían ser detectados como anomalías en naranja. Para ello definimos la siguiente funcion:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRgQ7lcjwbc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def anomaly_plotter(axis, anomalies, timespan, min, max):\n",
        "  for ai in anomalies:\n",
        "    if ai < timespan:\n",
        "        axis.plot([ai, ai], [min, max], 'orange')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg8wUonOxswi",
        "colab_type": "text"
      },
      "source": [
        "Analizamos gráficamente los resultados y verificamos que los mismos tienen sentido con los defectos encontrados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JFPJ3iKKPwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "señal = detrend(señal)      # quitamos la tendencia que agrega el ruido de línea y de los movimientos corporales\n",
        "peaks = getPeaks(señal, fs, time_cycle / 2, time_cycle / 10)\n",
        "\n",
        "myFilterARF = filterARF(500, 0.1)\n",
        "filtered, error = myFilterARF.train(peaks, señal)\n",
        "\n",
        "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, sharex=True)\n",
        "ax1.plot(t, señal)\n",
        "anomaly_plotter(axis=ax1, anomalies=errores, timespan=timespan, min=min(señal), max=max(señal))\n",
        "\n",
        "ax2.plot(t, peaks)\n",
        "ax3.plot(t, filtered)\n",
        "\n",
        "anomaly_plotter(axis=ax4, anomalies=errores, timespan=timespan, min=min(error), max=max(error))\n",
        "\n",
        "ax4.plot(t, abs(error))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7fnDb6THW-I",
        "colab_type": "text"
      },
      "source": [
        "## Algoritmo de detección\n",
        "\n",
        "Implementamos un detector de anomalías que utilice la señal de error del ARF."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcp7TGf1NLak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "thresholdError = 7.5\n",
        "\n",
        "fs = 360\n",
        "\n",
        "def getErrors(signal, periodSignal):\n",
        "  \"\"\"\n",
        "      signal: Señal de error, a partir de la cual se obtendrán las anomalias\n",
        "      periodSignal: Señal que vale 1 en el instante de tiempo en el que inicia un periodo de signal.\n",
        "                    0 en todo otro momento\n",
        "      ouput: Vector que tiene un 0 en aquellas posiciones que no se detecto anomalia\n",
        "                    y un 1 en aquellas en las que si se detecto anomalia\n",
        "      errorCount: cantidad total de anomalias en el arreglo output\"\"\"\n",
        "  acum = 0\n",
        "\n",
        "  output = np.zeros(len(signal))\n",
        "  wavgSum = 0\n",
        "  errorCount = 0\n",
        "\n",
        "  for i in range(len(signal)):\n",
        "      acum += signal[i]**2\n",
        "      wavgSum += signal[i]**2 * i\n",
        "\n",
        "      # Si inicia un nuevo periodo de la señal\n",
        "      if periodSignal[i] > 0.5:     \n",
        "          if acum > thresholdError:\n",
        "              wavg = int(round(wavgSum /acum))\n",
        "\n",
        "              output[wavg] = 1\n",
        "              errorCount += 1\n",
        "          wavgSum = 0\n",
        "          acum = 0 # reset\n",
        "\n",
        "  return output, errorCount"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FziQt2qcx5qv",
        "colab_type": "text"
      },
      "source": [
        "## Análisis numérico de la detección"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31VSEjppywdd",
        "colab_type": "text"
      },
      "source": [
        "Queremos evaluar ahora numéricamente el porcentaje de aciertos sobre fallidos, distinguiendo entre los siguientes casos:\n",
        "\n",
        "    1) Porcentaje de aciertos sobre fallidos totales\n",
        "\n",
        "    2) Porcentaje de aciertos sobre fallidos que caigan dentro de los falsos positivos (se dice que es anómalo cuando no lo es)\n",
        "\n",
        "    3) Porcentaje de aciertos sobre fallidos que caigan dentro del caso de los falsos negativos (se dice que no es anómalo cuando sí lo es)\n",
        "\n",
        "El criterio tomado por el grupo fue priorizar la ausencia de falsos negativos por sobre la ausencia de falsos positivos debido a las consecuencias amorales y negativas que un mal diagnóstico de este tipo podría frente a un paciente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXduJM-qJApv",
        "colab_type": "text"
      },
      "source": [
        "### Contrastar lo detectado con las anotaciones indicadas por la base de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AK6wTP5EQOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cuantificarError(erroresReales, erroresCalculados):\n",
        "    falsosPositivos = 0\n",
        "    verdaderosNegativos = 0\n",
        "\n",
        "    minDistance = 10 * fs\n",
        "\n",
        "    okRange = np.zeros(len(erroresReales))\n",
        "\n",
        "    # okRange en 1 indica que el filtro indica que hay anomalia\n",
        "    for i in range(len(erroresCalculados)):\n",
        "        if erroresCalculados[i] > 0.5:\n",
        "            okRange[i-minDistance:i+minDistance] = 1 \n",
        "\n",
        "    # se buscan aquellos luegares en los que halla una anomalia que no se detecta\n",
        "    for i in range(len(erroresReales)):\n",
        "        if erroresReales[i] > 0.5 and okRange[i] < 0.5:\n",
        "            verdaderosNegativos += 1\n",
        "\n",
        "    okRange = np.zeros(len(erroresReales))\n",
        "\n",
        "    # okRange en 1 indica que la base de datos indica que hay anomalia\n",
        "    for i in range(len(erroresReales)):\n",
        "        if erroresReales[i] > 0.5:\n",
        "            okRange[i - minDistance:i + minDistance] = 1\n",
        "\n",
        "    # se buscan aquellos luegares en los que el filtro dice que hay anomalia pero no la hay\n",
        "    for i in range(len(erroresCalculados)):\n",
        "        if erroresCalculados[i] and okRange[i] < 0.5:\n",
        "            falsosPositivos += 1\n",
        "\n",
        "    return falsosPositivos, verdaderosNegativos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpllJ0U3JYih",
        "colab_type": "text"
      },
      "source": [
        "Plot de las anomalias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Isqp9_QwMJ6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def anomaly_plotter(axis, anomalies, timespan, min, max):\n",
        "    for ai in anomalies:\n",
        "        if ai < timespan:\n",
        "          axis.plot([ai, ai], [0, max], 'orange')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tOgKTy-NAvf",
        "colab_type": "text"
      },
      "source": [
        "Ejecucion de la deteccion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPnvt4hjNNYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotSignal(code):\n",
        "\n",
        "    timespan = 1000000\n",
        "    time_cycle = 1.4\n",
        "    original = all_signals[code][\"upper\"] \n",
        "    t = np.arange(len(original)) / fs\n",
        "    errores = list(all_signals[code][\"anomalies\"].keys())\n",
        "    errores = [float(errores[i]) / fs for i in range(len(errores))]\n",
        "\n",
        "    señal = noise_filtering(signal=original)\n",
        "\n",
        "    peaksList, _ = find_peaks(señal, height=0.5, distance=time_cycle/4*fs)\n",
        "    peaks = np.zeros(len(señal))\n",
        "\n",
        "    impulse_distance = int(time_cycle/2*fs)\n",
        "\n",
        "    for peak in peaksList:\n",
        "        if peak - impulse_distance >= 0:\n",
        "            peaks[peak - impulse_distance] = 1\n",
        "\n",
        "    myFilterARF = filterARF(500, 0.01)\n",
        "    filtered, error = myFilterARF.train(peaks, señal)\n",
        "\n",
        "    fig, (ax0, ax1, ax2, ax3, ax4, ax5) = plt.subplots(6, sharex=True, sharey=True)\n",
        "    ax0.set_ylim(-2.5, 2.5)\n",
        "    ax3.set_ylim(-2.5, 2.5)\n",
        "\n",
        "    ax0.plot(t, original)\n",
        "\n",
        "    ax1.plot(t, señal)\n",
        "    anomaly_plotter(axis=ax1, anomalies=errores, timespan=timespan, min=min(señal), max=max(señal))\n",
        "\n",
        "    ax2.plot(t, peaks)\n",
        "    ax3.plot(t, filtered)\n",
        "\n",
        "    anomaly_plotter(axis=ax4, anomalies=errores, timespan=timespan, min=min(error), max=max(error))\n",
        "\n",
        "\n",
        "    ax4.plot(t, abs(error))\n",
        "    erroresCalculados, errorCount = getErrors(error, peaks)\n",
        "\n",
        "    ax5.plot(t, erroresCalculados)\n",
        "\n",
        "    erroresReales = np.zeros(len(original))\n",
        "\n",
        "    for a in errores:\n",
        "        erroresReales[int(round(a*fs))] = 1\n",
        "\n",
        "    return erroresReales, erroresCalculados, len(errores), errorCount"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaxnJWs2i2Hv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotSignal('112')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGQfy_iyJaE8",
        "colab_type": "text"
      },
      "source": [
        "### Probando la efectividad sobre la totalidad de las señales de la base de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M4QTkmgKqpD",
        "colab_type": "text"
      },
      "source": [
        "Generaremos un archivo .csv en el que se hallarán cuantificados los falsos positivos y negativos además de la efectividad del algoritmo aplicado a una señal. Definimos entonces las siguientes columnas para dicho archivo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0gZNp7ALNq2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = {\n",
        "        \"Caso\": [],\n",
        "        \"Falsos Positivos\": [],\n",
        "        \"Positivos\": [],\n",
        "        \"Verdaderos Negativos\": [],\n",
        "        \"Negativos\": [],\n",
        "        \"Efectividad 1\": [],\n",
        "        \"Efectividad 2\": []\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RtZHd_BLV4K",
        "colab_type": "text"
      },
      "source": [
        "Generamos el archivo para cada una de las señales de la base de datos. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC8nMF62NWrl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fs = 360\n",
        "\n",
        "for signal_name in all_signals.keys():\n",
        "\n",
        "    erroresReales, erroresCalculados, countReal, countCalculado = plotSignal(signal_name)\n",
        "\n",
        "    AnomaliaDetectadaErroneamente, anomaliasNoDetectadas = cuantificarError(erroresReales[90 * fs:], erroresCalculados[90 * fs:])\n",
        "\n",
        "    data[\"Caso\"].append(signal_name)\n",
        "    data[\"Anomalia Detectada Erroneamente\"].append(falsosPositivos)\n",
        "    data[\"Cantidad de supuestas anomalias\"].append(countCalculado)\n",
        "    data[\"Anomalias No Detectadas\"].append(anomaliasNoDetectadas)\n",
        "    data[\"Cantidad de anomalias reales\"].append(countReal)\n",
        "    data[\"Efectividad 1\"].append(100 - falsosPositivos / countCalculado * 100)\n",
        "    data[\"Efectividad 2\"].append(100 - anomaliasNoDetectadas / countReal * 100)\n",
        "\n",
        "    print(\"%s => %d/%d | %d/%d\" % (signal_name, falsosPositivos, countCalculado,anomaliasNoDetectadas, countReal))\n",
        "    plt.close()\n",
        "\n",
        "pd.DataFrame.from_dict(data).to_excel(\"Efectividad.xlsx\", sheet_name='Efectividad')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-xJCXe5N-ct",
        "colab_type": "text"
      },
      "source": [
        "### Grafico de los resultados\n",
        "Los resultados almaceneados en **Efectividad.xlsx** son a continuación graficados para tener una mejor visualización de los mismos.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GP_lKQM8OG7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "archivo = pd.read_excel(\"Efectividad.xlsx\")\n",
        "data = archivo.to_dict(\"list\")\n",
        "\n",
        "nombres = data[\"Caso\"]\n",
        "\n",
        "\n",
        "performance1 = 100 - np.divide(data[\"Anomalia Detectada Erroneamente\"] , data[\"Cantidad de supuestas anomalias\"])*100\n",
        "\n",
        "\n",
        "plt.rcdefaults()\n",
        "fig, ax = plt.subplots(figsize=(6, 15))\n",
        "y_pos = np.arange(len(nombres))\n",
        "ax.barh(y_pos, performance1, xerr=np.zeros(len(nombres)), align='center')\n",
        "\n",
        "ax.set_yticks(y_pos)\n",
        "ax.set_yticklabels(nombres)\n",
        "ax.invert_yaxis()\n",
        "\n",
        "ax.set_xlabel('1 - Falso positivo / Cantidad de supuestos positivos(%)')\n",
        "\n",
        "plt.savefig(\"Efectividad en detectados.png\")\n",
        "plt.close()\n",
        "\n",
        "plt.rcdefaults()\n",
        "fig, ax = plt.subplots(figsize=(6, 15))\n",
        "fig\n",
        "y_pos = np.arange(len(nombres))\n",
        "\n",
        "performance2 = 100 - np.divide(data[\"Anomalias No Detectadas\"], data[\"Cantidad de anomalias reales\"])*100\n",
        "ax.barh(y_pos, performance2, xerr=np.zeros(len(nombres)), align='center', color=\"orange\")\n",
        "\n",
        "ax.set_yticklabels(nombres)\n",
        "ax.set_yticks(y_pos)\n",
        "\n",
        "ax.invert_yaxis()\n",
        "\n",
        "ax.set_xlabel('1 - Anomalias No Detectadas / Cantidad de anomalias reales (%)')\n",
        "\n",
        "plt.savefig(\"Efectividad en existentes.png\")\n",
        "plt.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}